<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Learning on Ryan McCarl</title>
    <link>http://ryanmccarl.com/categories/learning/</link>
    <description>Recent content in Learning on Ryan McCarl</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 09 Oct 2015 05:49:37 +0000</lastBuildDate>
    <atom:link href="/categories/learning/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Developing a language-learning program (high-frequency sentence identifier)</title>
      <link>http://ryanmccarl.com/2015/10/09/developing-a-language-learning-program-high-frequency-sentence-identifier/</link>
      <pubDate>Fri, 09 Oct 2015 05:49:37 +0000</pubDate>
      
      <guid>http://ryanmccarl.com/2015/10/09/developing-a-language-learning-program-high-frequency-sentence-identifier/</guid>
      <description>&lt;p&gt;UPDATE: I devoted most of my nights and weekends this year to building the program described below with the help of Kostyantyn Grinchenko, an excellent Ukrainian freelance developer. Then, after realizing that we had stumbled upon a breakthrough idea that could revolutionize language learning and help many people become fluent readers of their target language, I assembled a remote team of freelance and volunteer developers, designers, native-speaker audio recorders, and translators to help me develop it into a webapp (and future mobile app): &lt;a href=&#34;https://wordbrewery.com&#34; target=&#34;_blank&#34;&gt;WordBrewery.com&lt;/a&gt;. Please help WordBrewery grow by &lt;a href=&#34;https://wordbrewery.com&#34; target=&#34;_blank&#34;&gt;trying it out&lt;/a&gt;, joining our &lt;a href=&#34;http://wordbrewery.us12.list-manage.com/subscribe?u=de5def825a669f96078a614d4&amp;amp;id=ccf98da72c&#34; target=&#34;_blank&#34;&gt;email list&lt;/a&gt;, &lt;a href=&#34;http://feeds.feedburner.com/LanguageUntapped&#34; target=&#34;_blank&#34;&gt;subscribing&lt;/a&gt; to our &lt;a href=&#34;https://wordbrewery.com/blog/&#34; target=&#34;_blank&#34;&gt;blog&lt;/a&gt;, following us on &lt;a href=&#34;https://www.facebook.com/WordBrewery/&#34; target=&#34;_blank&#34;&gt;Facebook&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/WordBrewery&#34; target=&#34;_blank&#34;&gt;Twitter&lt;/a&gt;, or taking a &lt;a href=&#34;https://docs.google.com/forms/d/1VLYcHdI5-FLlr5hMRJ1DzhLKDUzfkPvyI8Bx3bvvk3w/viewform&#34; target=&#34;_blank&#34;&gt;beta tester survey&lt;/a&gt;. Please &lt;a href=&#34;mailto:admin@wordbrewery.com&#34; target=&#34;_blank&#34;&gt;get in touch&lt;/a&gt; if you are interested in supporting the WordBrewery project as a donor, investor, advocate, or volunteer. Thank you for your support.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Over the past two months, I&amp;rsquo;ve been experimenting with outsourcing small personal digital projects to overseas freelancers on Upwork. The experience has been very positive so far. I&amp;rsquo;ve decided to devote a post to each of the tasks I outsource to give readers a sense of how freelancers and virtual assistants can both make one&amp;rsquo;s life easier in various ways and enable one to pursue projects and ideas despite lacking the time, expertise, or patience to implement them without outside help and delegation. I find Upwork and similar programs to be fascinating&amp;ndash;a fantastic, unambiguously positive example of open markets and the division of labor.&lt;/p&gt;

&lt;p&gt;I am very interested in finding efficient ways to learn things, especially languages. Language vocabulary is an example of the &amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/Pareto_principle&#34; target=&#34;_blank&#34;&gt;Pareto Principle&lt;/a&gt;&amp;rdquo; (also known as the &amp;ldquo;80-20 rule&amp;rdquo;), according to which, &amp;ldquo;for many events, roughly 80% of the effects come from 20% of the causes.&amp;rdquo; In the context of language learning, the rule fits the fact that the most common 1,000 words or so in a language account for about 90% of spoken speech in that language. Thus, the best way to quickly develop one&amp;rsquo;s practical vocabulary in a second language is to focus on a &lt;a href=&#34;https://fluent-forever.com/the-method/vocabulary/#.VhdQRBNViko&#34; target=&#34;_blank&#34;&gt;core vocabulary list&lt;/a&gt; of high-frequency words.&lt;/p&gt;

&lt;p&gt;This insight, however, most be paired with another well-established principle of literacy and language learning: it is far better to learn vocabulary by studying it in context rather than in the form of isolated words in a list or on flash cards. Accordingly, language learners should study sentences, not words.&lt;/p&gt;

&lt;p&gt;I thus came up with the idea for a language learning tool that identifies sentences with numerous high-frequency words: such sentences are especially valuable for language learners. But I could not find any program or tool that does this seemingly straightforward task. I know some basic computer programming, but for the near future I will lack the time and expertise to create such a tool from scratch myself. So I&amp;rsquo;ve decided to partially &lt;a href=&#34;https://www.upwork.com/jobs/~0160ccc97b753712cc&#34; target=&#34;_blank&#34;&gt;outsource it&lt;/a&gt;, and I&amp;rsquo;ve found several overseas programmers who appear to be very capable of creating the program as I envision it. Here is the job as posted on Upwork:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;_Language learning tool: High-frequency sentence identifier&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Purpose: allow language learners to identify and collect sentences that are particularly valuable to study and memorize because they use several high-frequency words and do not include any obscure words.&lt;/p&gt;

&lt;p&gt;Suggested mode of operation:&lt;/p&gt;

&lt;p&gt;-For each language, the program would draw upon data from at least two sources:&lt;/p&gt;

&lt;p&gt;(1) a spreadsheet (CSV) or other easily manipulable data storage mechanism in which the 10,000 or 20,000 most column words of a language are pasted. In column one, assign the word a frequency score: the higher the frequency, the higher the score. So, for example, if the list has 500 words, the least common (most obscure) word in that list could be assigned a score of &amp;ldquo;1,&amp;rdquo; and the most common word in the list could be assigned a score of 500.&lt;/p&gt;

&lt;p&gt;(2) a list or corpus of example sentences, whether scraped in real-time from Wikipedia or other websites (e.g. Project Gutenberg, Tatoeba), or manually created and made available in a text file. For example, an Anki deck of example sentences (&lt;a href=&#34;https://ankiweb.net/shared/info/1715094364&#34; target=&#34;_blank&#34;&gt;https://ankiweb.net/shared/info/1715094364&lt;/a&gt;) can be exported into a text file:&lt;/p&gt;

&lt;p&gt;-El ministro ha informado a la nación sobre la guerra. (The prime minister has informed the nation about the war.)
-Él tragaba sus bebidas rápidamente. (He used to gulp his drinks too quickly.)&lt;/p&gt;

&lt;p&gt;-The program would iterate over the target-language example sentences, scoring each sentence for its potential value to the language-learner. Sentences that use several high-frequency words would receive a higher score&amp;ndash;and thus be more likely to be presented to the user. Sentences that include an uncommon or obscure word that does not appear on the frequency list at all (e.g., a word that is not among the 20,000 most common words of a language) would be penalized and less likely to be presented to the user.&lt;/p&gt;

&lt;p&gt;-The program would have some mechanism for avoiding or reducing repetitiveness so that it brings in diverse sentences that do not repeat the same high-frequency words over and over. Ideally, this would be flexible so it does not completely disqualify a sentence just because one of its words was already used: this would disqualify too many sentences. But the program could somehow penalize sentences that use words that have already appeared in sentences the program has selected.&lt;/p&gt;

&lt;p&gt;-The program would produce a CSV or text file of the sentences it has selected. The user should be able to instruct the program to return a certain number of sentences.&lt;/p&gt;

&lt;p&gt;-To avoid repetitive results in repeat uses, the program should include an element of randomness in selecting sentences for presentation to the user. Ideally, the user should be able to set the randomness level. A randomness level of 0, for example, could remove all randomness and simply return the highest-scoring sentences, while a randomness level of 100 could return a completely random set of sentences.&lt;/p&gt;

&lt;p&gt;Technical necessities:&lt;/p&gt;

&lt;p&gt;-The program needs to be able to handle non-English characters and words such as French/Spanish/Portuguese accented characters as well as Japanese, Chinese, Korean, and Thai. For the Asian languages, the program will also need to be able to cope with sentences that do not separate words with spaces.&lt;/p&gt;

&lt;p&gt;-The program must be able to handle sentence data formatted in varying ways from diverse sources. For example, it should use regular expressions or other tools to automatically identify the delimiters that signal where each sentence begins and ends. Whether the program is iterating over a text file exported from Anki or a messy webpage, the program should return only sentences&amp;ndash;not single words, multiple sentences, translations, HTML tags, etc.&lt;/p&gt;

&lt;p&gt;Further ideas:&lt;/p&gt;

&lt;p&gt;-I would like the scoring mechanism to be flexible so I can experiment with different ways of scoring the sentences.&lt;/p&gt;

&lt;p&gt;-It would be a bonus if the program could somehow be used to identify sentences that use a particular grammatical pattern or construction.&lt;/p&gt;

&lt;p&gt;-It would further be helpful if the search mechanism accepted close matches to words on the frequency list to account for different verb conjugations, spelling variations, etc.&lt;/p&gt;

&lt;p&gt;-I would like it if the program could, at the user&amp;rsquo;s option, show its work by: (1) showing or hiding each sentence&amp;rsquo;s frequency score in its results, and (2) returning not only sentences, but also&amp;ndash;for each sentence&amp;ndash;the high-frequency words the program found in that sentence, and those words&amp;rsquo; frequency score._&lt;/p&gt;

&lt;p&gt;Please &lt;a href=&#34;mailto:ryan.mccarl@gmail.com&#34; target=&#34;_blank&#34;&gt;email me&lt;/a&gt; if you have suggestions or would like to help out with creating the program.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning blackjack</title>
      <link>http://ryanmccarl.com/2015/09/26/learning-blackjack/</link>
      <pubDate>Sat, 26 Sep 2015 03:48:50 +0000</pubDate>
      
      <guid>http://ryanmccarl.com/2015/09/26/learning-blackjack/</guid>
      <description>&lt;p&gt;In two weeks, I am going to Las Vegas for my brother&amp;rsquo;s bachelor party. It is inevitable that I will gamble a bit and lose that money which I gamble; I consider this an entertainment expense, not an opportunity to make money. Nevertheless, it seems wise to attempt to limit the damage—or at least acquire some knowledge as a consolation prize—by becoming well-informed about precisely how the casino will be taking my money.&lt;/p&gt;

&lt;p&gt;Additionally, for years I have wanted to learn statistics. In second grade, I kept “stat books” in which I attempted to study the relative strengths and weaknesses of football and hockey teams and make predictions about who would defeat whom. In eleventh grade, however, my math education derailed, and I never got around to learning statistics. When I have tried to do so, I have been put off by the giant equations with their symbols and subscripts, and dismissed the topic as something I am fated to never understand. &lt;/p&gt;

&lt;p&gt;So, motivated by these two complementary aims, I&amp;rsquo;ve decided to learn a casino game, and (I think) the one with the best odds is Blackjack. Accordingly, I&amp;rsquo;ve done some reading on Blackjack strategy over the past two days, and I&amp;rsquo;ll post what I have learned. Credit for any correct assertions goes to Jay Moore&amp;rsquo;s “The Most Powerful Blackjack Manual” and the iPhone app “BlackJack 101 Free.” It seems there is some disagreement about strategy at the margins—which is exactly what makes a game fun, anyway—so do not take what follows as The Truth. I am a confessed novice: I know nothing about this subject except, perhaps, for what follows.&lt;/p&gt;

&lt;p&gt;As introduction, the object of blackjack is for the player to defeat the dealer; the player and the dealer each get two cards; all face cards (J, Q, K) are worth 10; the object is to draw cards amounting to a number as close as possible to 21 without going over 21; and if either the dealer or the player goes over 21, that is called a “bust.” The dealer deals the player&amp;rsquo;s cards face-up, but the dealer himself keeps one card face up (the “upcard”) and one card face down (the “hole card”). To “hit” is to request another card (at the risk of “busting,” i.e. going over 21), to “stand” is to refuse additional cards (at the risk of having a lower total than the dealer), to “split” if one is dealt a pair (e.g. two fives or two aces) is to double one&amp;rsquo;s bet and play two separate hands simultaneously, and to “double down” is to double one&amp;rsquo;s initial bet and accept only one additional card. The dealer must follow a particular script, usually “hitting” if his cards total 16 or fewer points, but “standing” if his cards total more than 16.&lt;/p&gt;

&lt;p&gt;Strategy to come in the next post.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
